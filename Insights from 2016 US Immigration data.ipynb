{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Insights about US Immigration 2016\n",
    "### Data Engineering Capstone Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = \"/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/jvm/java-8-openjdk-amd64/bin\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, when, isnull, udf, col, dayofmonth, year, month, monotonically_increasing_id\n",
    "\n",
    "# AWS credentials to access and use S3\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('s3.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creates SparkSessions\n",
    "Reads and loads datasets to be used for data modeling\n",
    "'''\n",
    "\n",
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "# 2 different data formats\n",
    "immig_df=spark.read.load('./sas_data')\n",
    "demo_df = spark.read.json('us-cities-demographics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def col_cleaner(df):  \n",
    "    \n",
    "    '''\n",
    "    Eliminates columns that have more than 50% of cells population as empty, duplicate records and empty records\n",
    "    \n",
    "    To be used for cleaning data for dimension tables and fact table; 'time', 'person', 'arrival_event'\n",
    "\n",
    "    '''\n",
    "    \n",
    "    df_count = df.count()\n",
    "\n",
    "    # Eliminate columns that have less than 50% population\n",
    "    \n",
    "    col_pop = df.select([(count(when(isnull(c), c)) / df_count).alias(c) for c in df.columns])\n",
    "    #col_pop.show(n=1,vertical=True, truncate=False)\n",
    "    \n",
    "    col_to_elimin = [key for (key, value) in col_pop.head().asDict().items() if value > 0.5]\n",
    "    #print(col_to_elimin)\n",
    "\n",
    "    if col_to_elimin:\n",
    "        cleaned_df = df.drop(*col_to_elimin)\n",
    "        cleaned_df = cleaned_df.dropDuplicates()\n",
    "        cleaned_df = cleaned_df.dropna(how='all')\n",
    "  \n",
    "        return cleaned_df\n",
    "    else:\n",
    "        cleaned_df = df.dropDuplicates()\n",
    "        cleaned_df = cleaned_df.dropna(how='all')\n",
    "\n",
    "        return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaned_immig_data = col_cleaner(immig_df)\n",
    "cleaned_demo_data = col_cleaner(demo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_immig_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(len(immig_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-----+---+\n",
      "|day_of_arrival|year|month|day|\n",
      "+--------------+----+-----+---+\n",
      "|    2016-04-01|2016|    4|  1|\n",
      "+--------------+----+-----+---+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Creates dimension table for time\n",
    "'''\n",
    "\n",
    "get_timestamp = udf(lambda x : (datetime.date(1960, 1, 1) + datetime.timedelta(days=x)).isoformat() if x else none)\n",
    "\n",
    "formatted_arrdate = cleaned_immig_data.withColumn('timestamp', get_timestamp(cleaned_immig_data.arrdate))\n",
    "#df.show(3)\n",
    "\n",
    "dimen_time_table = formatted_arrdate.select(\\\n",
    "    col(\"timestamp\").alias('day_of_arrival'),\n",
    "    year(\"timestamp\").alias('year'),\n",
    "    month('timestamp').alias('month'),\n",
    "    dayofmonth('timestamp').alias('day'))\n",
    "\n",
    "dimen_time_table.show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+----------+----------+---------------+-----------------+----------------+------------------+----------------------+------------------+\n",
      "| id|   city|     state|state_code|median_age|male_population|female_population|total_population|number_of_veterans|number_of_foreign_born|avg_household_size|\n",
      "+---+-------+----------+----------+----------+---------------+-----------------+----------------+------------------+----------------------+------------------+\n",
      "|  0|Lynwood|California|        CA|      29.4|          35634|            36371|           72005|               776|                 28061|              4.43|\n",
      "+---+-------+----------+----------+----------+---------------+-----------------+----------------+------------------+----------------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Creates dimension table for US States\n",
    "'''\n",
    "\n",
    "dimen_state_table = cleaned_demo_data.withColumn('id', monotonically_increasing_id())\n",
    "\n",
    "dimen_state_table = dimen_state_table.select(['id','City', 'State', 'State Code', 'Median Age', 'Male Population', 'Female Population', 'Total Population', 'Number of Veterans', 'Foreign-born', 'Average Household Size'])\n",
    "\n",
    "dimen_state_table = dimen_state_table.withColumnRenamed('City', 'city') \\\n",
    "                    .withColumnRenamed('State','state') \\\n",
    "                    .withColumnRenamed('State Code', 'state_code') \\\n",
    "                    .withColumnRenamed('Median Age', 'median_age') \\\n",
    "                    .withColumnRenamed('Male Population', 'male_population') \\\n",
    "                    .withColumnRenamed('Female Population', 'female_population') \\\n",
    "                    .withColumnRenamed('Total Population', 'total_population') \\\n",
    "                    .withColumnRenamed('Number of Veterans', 'number_of_veterans') \\\n",
    "                    .withColumnRenamed('Foreign-born','number_of_foreign_born') \\\n",
    "                    .withColumnRenamed('Average Household Size','avg_household_size')\n",
    "\n",
    "dimen_state_table.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+---------------+------+------+-------+------+--------+\n",
      "| id|cicid|i94bir|         admnum|i94cit|i94res|i94mode|i94mon|visatype|\n",
      "+---+-----+------+---------------+------+------+-------+------+--------+\n",
      "|  0|474.0|  25.0|5.5410441233E10| 103.0| 103.0|    2.0|   4.0|      WT|\n",
      "+---+-----+------+---------------+------+------+-------+------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Creates dimension table for persons arriving in US\n",
    "'''\n",
    "\n",
    "dimen_person_table = cleaned_immig_data.select(['cicid', 'i94bir', 'admnum', 'i94cit', 'i94res', 'i94mode', 'i94mon', 'visatype'])\n",
    "\n",
    "dimen_person_table = dimen_person_table.withColumn('id', monotonically_increasing_id())\n",
    "\n",
    "dimen_person_table = dimen_person_table.select(['id', 'cicid', 'i94bir', 'admnum', 'i94cit', 'i94res', 'i94mode', 'i94mon', 'visatype'])\n",
    "\n",
    "dimen_person_table.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+-------+-------+------+\n",
      "|cicid|arrdate|depdate|i94mode|i94addr|i94mon|\n",
      "+-----+-------+-------+-------+-------+------+\n",
      "|474.0|20545.0|20547.0|    2.0|   null|   4.0|\n",
      "+-----+-------+-------+-------+-------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Creates fact table for arrival events\n",
    "'''\n",
    "\n",
    "fact_table = cleaned_immig_data.select(['cicid', 'arrdate', 'depdate', 'i94mode', 'i94addr','i94mon']) # need to add column with duration of visit/residence, in days\n",
    "\n",
    "### Returning the following table with added column caused 'Java Runtime error'\n",
    "#get_timestamp = udf(lambda x : (datetime.date(1960, 1, 1) + datetime.timedelta(days=x)).isoformat() if x else none)\n",
    "#formatted_arrdate = fact_table.withColumn('timestamp', get_timestamp(fact_table.arrdate))\n",
    "\n",
    "fact_table.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Cleans data for dimension tables and fact table; 'time', 'person', 'arrival_event'\n",
    "Creates dimension tables and fact table and uploads to S3, partitioned by respective attributes\n",
    "'''\n",
    "\n",
    "### Create F/D tables \n",
    "\n",
    "# Writing time table to S3\n",
    "#dimen_time_table.write.partitionBy('year','month').parquet('s3a://capstone23/time', \"overwrite\")\n",
    "\n",
    "# Writing persons table to S3\n",
    "dimen_person_table.write.partitionBy('i94mon').parquet('s3a://capstone23/person', \"overwrite\")\n",
    "#spark.read.parquet('s3a://capstone23/person/_temporary/0/task_20210629020203_0009_m_000000/part-00000-4dc1173c-33b1-4534-a2aa-bc3d291a54ce-c000.snappy.parquet').show()\n",
    "\n",
    "# Writing fact table to S3\n",
    "###fact_arrival_event_table.write.partitionBy('i94mon').parquet('s3a://capstone23/arrival_event', \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dimen_state_table.write.partitionBy('state').parquet('s3a://capstone23/state', \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Data quality checks\n",
    "\n",
    "1. Checking if written files in S3 are populated\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv ('us-cities-demographics.csv',sep=';')\n",
    "jason = df.to_json ('./us-cities-demographics.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " Average Household Size | 2.6                \n",
      " City                   | Silver Spring      \n",
      " Count                  | 25924              \n",
      " Female Population      | 41862.0            \n",
      " Foreign-born           | 30908.0            \n",
      " Male Population        | 40601.0            \n",
      " Median Age             | 33.8               \n",
      " Number of Veterans     | 1562.0             \n",
      " Race                   | Hispanic or Latino \n",
      " State                  | Maryland           \n",
      " State Code             | MD                 \n",
      " Total Population       | 82463              \n",
      "-RECORD 1------------------------------------\n",
      " Average Household Size | 2.39               \n",
      " City                   | Quincy             \n",
      " Count                  | 58723              \n",
      " Female Population      | 49500.0            \n",
      " Foreign-born           | 32935.0            \n",
      " Male Population        | 44129.0            \n",
      " Median Age             | 41.0               \n",
      " Number of Veterans     | 4147.0             \n",
      " Race                   | White              \n",
      " State                  | Massachusetts      \n",
      " State Code             | MA                 \n",
      " Total Population       | 93629              \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.json('us-cities-demographics.json').show(2, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Data Quality Checks\n",
    "\n",
    "First check compares number of columns between processed and raw datasets.\n",
    "Second check compares number of records between processed and raw datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's a difference in number of columns between processed and raw datasets.\n",
      " This is due to columns having more than 50% of population as null.\n",
      " Processed dataset has 24 columns.\n",
      " Raw dataset has 28 columns.\n",
      "Processed and raw datasets contain the same number of columns: 12\n"
     ]
    }
   ],
   "source": [
    "def diff_columns(raw_df, processed_df):\n",
    "    \n",
    "    '''\n",
    "    This check compares number of columns between processed and raw datasets\n",
    "    '''\n",
    "    \n",
    "    raw_df_columns = len(raw_df.columns)\n",
    "    processed_df_columns = len(processed_df.columns)\n",
    "    \n",
    "    if(len(raw_df.columns) == len(processed_df.columns)):\n",
    "        print(f\"Processed and raw datasets contain the same number of columns: {raw_df_columns}\")\n",
    "    else:\n",
    "        print(f\"There's a difference in number of columns between processed and raw datasets.\\n This is due to columns having more than 50% of population as null.\\n Processed dataset has {processed_df_columns} columns.\\n Raw dataset has {raw_df_columns} columns.\")\n",
    "        \n",
    "diff_columns(immig_df, cleaned_immig_data)\n",
    "diff_columns(demo_df, cleaned_demo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking between processed and raw data, there were no duplicates and empty rows in raw data\n",
      "Checking between processed and raw data, there were no duplicates and empty rows in raw data\n"
     ]
    }
   ],
   "source": [
    "def diff_records(raw_df, processed_df):\n",
    "    \n",
    "    '''\n",
    "    This check compares number of records between processed and raw datasets\n",
    "    '''\n",
    "    \n",
    "    processed_df_count = processed_df.count()\n",
    "    raw_df_count = raw_df.count()\n",
    "    \n",
    "    if (raw_df_count == processed_df_count):\n",
    "        print('Checking between processed and raw data, there were no duplicates and empty rows in raw data')\n",
    "    else:\n",
    "        missing_records = raw_df_count - processed_df_count\n",
    "        print(f'Checking between processed and raw data, there were {missing_records} duplicates and empty rows in raw data')\n",
    "        \n",
    "diff_records(immig_df, cleaned_immig_data)\n",
    "diff_records(demo_df, cleaned_demo_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
